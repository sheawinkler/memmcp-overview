<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Context Lattice | Private memory fabric for AI agents</title>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  <main class="container">
    <header class="topbar">
      <a class="brand" href="index.html">
        <span class="brand-mark" aria-hidden="true"></span>
        <span class="brand-label">Context Lattice</span>
      </a>
      <nav class="nav" aria-label="Primary">
        <a class="active" href="index.html">Home</a>
        <a href="updates.html">Updates</a>
        <a href="README.md">README</a>
        <a href="v1/">v1</a>
      </nav>
    </header>

    <section class="hero">
      <span class="badge">Private memory layer for agents</span>
      <h1>Fix context drift before it burns your token budget.</h1>
      <p class="sub">
        Context Lattice (memMCP) gives agents reusable memory with HTTP MCP, federated retrieval,
        durable fanout, and storage guardrails so quality and costs remain stable under load.
      </p>
      <ul class="chips">
        <li>HTTP-only MCP</li>
        <li>Federated retrieval</li>
        <li>Durable outbox fanout</li>
        <li>Learning rerank schema</li>
        <li>Letta RAG support</li>
        <li>Retention controls</li>
      </ul>
      <div class="cta-row">
        <a class="cta primary" href="mailto:pilot@contextlattice.io?subject=Context%20Lattice%20Pilot">Book a pilot</a>
        <a class="cta secondary" href="updates.html">Read updates</a>
      </div>
    </section>

    <section class="section">
      <div class="grid">
        <article class="card">
          <div class="kicker">What it solves</div>
          <h3>Memory quality + cost control</h3>
          <p>Replace repetitive long-context stuffing with reusable memory retrieval and sink durability.</p>
        </article>
        <article class="card">
          <div class="kicker">How it runs</div>
          <h3>Local first, enterprise path ready</h3>
          <p>Run on your machine now, then graduate to managed deployment with policy and access controls.</p>
        </article>
        <article class="card">
          <div class="kicker">Latest platform step</div>
          <h3>Self-protecting orchestrator</h3>
          <p>Fanout coalescer, Letta admission control, and retention workers reduce backlog and storage pressure.</p>
        </article>
      </div>
    </section>

    <section class="section">
      <article class="card">
        <div class="kicker">Learning retrieval</div>
        <h3>Orchestrator gets better at memory recall over time</h3>
        <p class="spotlight">
          The orchestrator uses a learning schema from feedback signals to rerank results and improve
          retrieval precision over time. This is reinforced by RAG through Letta archival memory,
          alongside Qdrant, Mongo raw, MindsDB, and memory-bank fallback.
        </p>
        <p class="muted-note">Read the detailed rollout notes on the <a href="updates.html">Updates page</a>.</p>
      </article>
    </section>

    <section class="section">
      <div class="kicker">How it all works together</div>
      <article class="card">
        <h3>Unified write + retrieval loop through the orchestrator</h3>
        <p>
          Every write enters through the orchestrator, which records durable raw data, fans out to specialized stores,
          and continuously protects queue and storage health. Every search comes back through the same orchestrator so
          results can be fused, reranked, and improved over time from feedback.
        </p>
        <ul class="chips">
          <li>Write intake</li>
          <li>Outbox fanout</li>
          <li>Federated search</li>
          <li>Learning rerank</li>
          <li>Retention + guardrails</li>
        </ul>
      </article>
    </section>

    <section class="section">
      <div class="kicker">Service map</div>
      <h2>Why each component exists</h2>
      <div class="grid component-grid">
        <article class="card component-card">
          <h3>Orchestrator</h3>
          <p><strong>Benefit:</strong> one control plane for writes, retrieval, and policy.</p>
          <p><strong>Why:</strong> central coordination is what allows multi-source ranking and learning to compound.</p>
        </article>
        <article class="card component-card">
          <h3>Memory Bank MCP</h3>
          <p><strong>Benefit:</strong> canonical project/file context store.</p>
          <p><strong>Why:</strong> keeps user-facing memory deterministic and compatible with MCP-native clients.</p>
        </article>
        <article class="card component-card">
          <h3>Qdrant</h3>
          <p><strong>Benefit:</strong> high-speed semantic recall.</p>
          <p><strong>Why:</strong> vector retrieval gives broad relevance quickly before deeper reranking.</p>
        </article>
        <article class="card component-card">
          <h3>Mongo Raw</h3>
          <p><strong>Benefit:</strong> durable source-of-truth write ledger.</p>
          <p><strong>Why:</strong> protects recoverability and enables repair/rehydrate workflows.</p>
        </article>
        <article class="card component-card">
          <h3>MindsDB</h3>
          <p><strong>Benefit:</strong> SQL-friendly analytics and structured querying.</p>
          <p><strong>Why:</strong> complements semantic search with tabular and operational insight paths.</p>
        </article>
        <article class="card component-card">
          <h3>Letta (RAG memory)</h3>
          <p><strong>Benefit:</strong> long-horizon archival context for agent reasoning.</p>
          <p><strong>Why:</strong> deep memory context improves difficult recall beyond nearest-neighbor hits.</p>
        </article>
        <article class="card component-card">
          <h3>Fanout Outbox</h3>
          <p><strong>Benefit:</strong> resilient async delivery with retries, coalescing, and admission control.</p>
          <p><strong>Why:</strong> prevents sink instability from breaking ingestion reliability.</p>
        </article>
        <article class="card component-card">
          <h3>Retention + Telemetry</h3>
          <p><strong>Benefit:</strong> bounded storage growth and observable runtime behavior.</p>
          <p><strong>Why:</strong> operational stability is required for learning retrieval to stay trustworthy.</p>
        </article>
      </div>
    </section>

    <section class="section">
      <article class="card">
        <div class="kicker">Why this boosts learning retrieval impact</div>
        <h3>Learning is strongest when memory is both rich and reliable</h3>
        <p>
          The orchestrator's learning schema can only improve ranking if retrieval sources stay healthy, durable,
          and synchronized. This architecture makes that possible: Qdrant provides fast candidates, Letta supplies
          deeper RAG context, Mongo guarantees recovery, MindsDB adds structured recall, and guardrails keep the
          full loop from collapsing under pressure.
        </p>
      </article>
    </section>

    <footer class="footer">
      <span>Context Lattice public overview</span>
      <span>Private by default. MCP-compatible by design.</span>
    </footer>
  </main>
</body>
</html>
